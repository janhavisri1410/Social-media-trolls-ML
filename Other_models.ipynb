{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd07bf5ba559c6092108d1c79914ad4f810e25cf03a64012019e402d699b8cb2028",
   "display_name": "Python 3.6.9  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7bf5ba559c6092108d1c79914ad4f810e25cf03a64012019e402d699b8cb2028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text as text2\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy as np, textblob, string\n",
    "from sklearn.utils import shuffle\n",
    "import operator as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, is_neural_net=False, should_do_common=False):\n",
    "\t# fit the training dataset on the classifier\n",
    "\tclassifier.fit(feature_vector_train, label)\n",
    "\t\n",
    "\ttrain_preds = classifier.predict(feature_vector_train)\n",
    "\ttest_preds = classifier.predict(feature_vector_test)\n",
    "\n",
    "\t# stop_words = text2.ENGLISH_STOP_WORDS.union([\"http\", \"https\", \"amp\", \"amb\"])\n",
    "\t\n",
    "\tif is_neural_net:\n",
    "\t\ttest_preds = test_preds.argmax(axis=-1)\n",
    "\n",
    "\tif should_do_common:\n",
    "\t    feature_names = count_vect.get_feature_names()\n",
    "\t    diff = classifier.feature_log_prob_[1,:] - np.max(classifier.feature_log_prob_[0:])\n",
    "\n",
    "\t    name_diff = {}\n",
    "\t    for i in range(len(feature_names)):\n",
    "\t       name_diff[feature_names[i]] = diff[i]\n",
    "\n",
    "\t       names_diff_sorted = sorted(name_diff.items(), key = op.itemgetter(1), reverse = True)\n",
    "\t    c = 0\n",
    "\t    i = 0\n",
    "\t    while c < 50:\n",
    "\t       if names_diff_sorted[i][0] in stop_words or len(names_diff_sorted[i][0]) <= 2:\n",
    "\t       \t i += 1\n",
    "\t       \t continue\n",
    "\t       print(names_diff_sorted[i])\n",
    "\t       c += 1\n",
    "\t       i += 1\n",
    "\t\n",
    "\ttrain_acc = metrics.accuracy_score(train_preds, train_y)\n",
    "\ttest_acc = metrics.accuracy_score(test_preds, test_y)\n",
    "\tcm = metrics.confusion_matrix(test_y, test_preds)\n",
    "\tf1 = metrics.f1_score(test_y, test_preds)\n",
    "\tprint('Train Accuracy: ', train_acc)\n",
    "\tprint('Test Accuracy: ', test_acc)\n",
    "\tprint('Confusion matrix: ', cm)\n",
    "\tprint('F1_score: ', f1)\n",
    "\treturn (test_acc, cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of datapoints:  11898\nPositive labels:  4541\nNegative labels:  7357\n"
     ]
    }
   ],
   "source": [
    "# load positive labels\n",
    "pos = open('Dataset/Positive_tweets(10000).csv').read()\n",
    "npos = 0\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(pos.split(\"\\n\")):\n",
    "    content = line.split(',')\n",
    "    if len(content) < 4:\n",
    "    \tcontinue;\n",
    "    if content[4] != \"English\":\n",
    "    \tcontinue;\n",
    "    labels.append(1)\n",
    "    texts.append(content[2])\n",
    "    npos += 1\n",
    "\n",
    "# load negative labels (random tweets)\n",
    "neg = open('Dataset/Negative_tweets(10000).txt').read()\n",
    "nneg = 0\n",
    "for i, line in enumerate(neg.split(\"\\n\")):\n",
    "    words = line.split(\" \")\n",
    "    newst = \"\"\n",
    "    for j in range(len(words)):\n",
    "        if(words[j].startswith(\"http\")):\n",
    "            break\n",
    "        newst = newst + \" \" + words[j]\n",
    "    newst = newst.strip()\n",
    "    if(newst == \"\"):\n",
    "        continue\n",
    "    \n",
    "    labels.append(0)\n",
    "    texts.append(newst)\n",
    "    nneg += 1\n",
    "\n",
    "texts, labels = shuffle(texts, labels)\n",
    "\n",
    "print('Total number of datapoints: ', len(labels))\n",
    "print('Positive labels: ', npos)\n",
    "print('Negative labels: ', nneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of training set:  9518\n",
      "Size of Test set: 2380\n",
      "/home/kps/Desktop/sem6/ML-Project-Bots-in-the-Net-Applying-Machine-Learning-to-Identify-Social-Media-Trolls/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], train_size=0.8,random_state=42)\n",
    "\n",
    "print('Size of training set: ', len(train_x))\n",
    "print('Size of Test set:', len(test_x))\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "\n",
    "binary_count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', binary=True)\n",
    "binary_count_vect.fit(trainDF['text'])\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "binary_xtrain_count = binary_count_vect.transform(train_x)\n",
    "binary_xtest_count = binary_count_vect.transform(test_x)\n",
    "\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xtest_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nNB, Binary Count Vectors: \nTrain Accuracy:  0.9833998739230931\nTest Accuracy:  0.9651260504201681\nConfusion matrix:  [[1461   19]\n [  64  836]]\nF1_score:  0.9527065527065527\n\nNB, Count Vectors: \nTrain Accuracy:  0.982769489388527\nTest Accuracy:  0.9613445378151261\nConfusion matrix:  [[1458   22]\n [  70  830]]\nF1_score:  0.9474885844748859\n\nNB, WordLevel TF-IDF: \nTrain Accuracy:  0.9736289136373187\nTest Accuracy:  0.9558823529411765\nConfusion matrix:  [[1463   17]\n [  88  812]]\nF1_score:  0.9392712550607288\n\nNB, N-Gram Vectors: \nTrain Accuracy:  0.9296070603067872\nTest Accuracy:  0.9042016806722689\nConfusion matrix:  [[1425   55]\n [ 173  727]]\nF1_score:  0.8644470868014269\n\nNB, CharLevel Vectors: \nTrain Accuracy:  0.960075646144148\nTest Accuracy:  0.9525210084033613\nConfusion matrix:  [[1459   21]\n [  92  808]]\nF1_score:  0.9346443030653557\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "print(\"\\nNB, Binary Count Vectors: \")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "print(\"\\nNB, Count Vectors: \")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "print(\"\\nNB, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "print(\"\\nNB, N-Gram Vectors: \")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "print(\"\\nNB, CharLevel Vectors: \")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "LR, Binary Count Vectors: \n",
      "/home/kps/Desktop/sem6/ML-Project-Bots-in-the-Net-Applying-Machine-Learning-to-Identify-Social-Media-Trolls/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "Train Accuracy:  0.994851859634377\n",
      "Test Accuracy:  0.9626050420168067\n",
      "Confusion matrix:  [[1453   27]\n",
      " [  62  838]]\n",
      "F1_score:  0.9495750708215297\n",
      "\n",
      "LR, Count Vectors: \n",
      "Train Accuracy:  0.9946417314561883\n",
      "Test Accuracy:  0.9638655462184874\n",
      "Confusion matrix:  [[1457   23]\n",
      " [  63  837]]\n",
      "F1_score:  0.9511363636363638\n",
      "\n",
      "LR, WordLevel TF-IDF: \n",
      "Train Accuracy:  0.9763605799537718\n",
      "Test Accuracy:  0.9525210084033613\n",
      "Confusion matrix:  [[1469   11]\n",
      " [ 102  798]]\n",
      "F1_score:  0.9338794616734932\n",
      "\n",
      "LR, N-Gram Vectors: \n",
      "Train Accuracy:  0.9108005883588989\n",
      "Test Accuracy:  0.8865546218487395\n",
      "Confusion matrix:  [[1459   21]\n",
      " [ 249  651]]\n",
      "F1_score:  0.8282442748091604\n",
      "\n",
      "LR, CharLevel Vectors: \n",
      "Train Accuracy:  0.9863416684177349\n",
      "Test Accuracy:  0.9810924369747899\n",
      "Confusion matrix:  [[1473    7]\n",
      " [  38  862]]\n",
      "F1_score:  0.9745618993781798\n"
     ]
    }
   ],
   "source": [
    "# LR on Count Vectors\n",
    "print(\"\\nLR, Binary Count Vectors: \")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# Linear Classifier on Count Vectors\n",
    "print(\"\\nLR, Count Vectors: \")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "print(\"\\nLR, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "print(\"\\nLR, N-Gram Vectors: \")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "print(\"\\nLR, CharLevel Vectors: \")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "SVM, Binary Count Vectors: \n",
      "Train Accuracy:  0.9998949359109056\n",
      "Test Accuracy:  0.9642857142857143\n",
      "Confusion matrix:  [[1459   21]\n",
      " [  64  836]]\n",
      "F1_score:  0.9516220830961867\n",
      "\n",
      "SVM, Count Vectors: \n",
      "Train Accuracy:  1.0\n",
      "Test Accuracy:  0.9600840336134454\n",
      "Confusion matrix:  [[1463   17]\n",
      " [  78  822]]\n",
      "F1_score:  0.9453709028177113\n",
      "\n",
      "SVM, WordLevel TF-IDF: \n",
      "Train Accuracy:  0.9942214750998108\n",
      "Test Accuracy:  0.9613445378151261\n",
      "Confusion matrix:  [[1444   36]\n",
      " [  56  844]]\n",
      "F1_score:  0.9483146067415731\n",
      "\n",
      "SVM, N-Gram Vectors: \n",
      "Train Accuracy:  0.9449464173145619\n",
      "Test Accuracy:  0.8957983193277311\n",
      "Confusion matrix:  [[1418   62]\n",
      " [ 186  714]]\n",
      "F1_score:  0.8520286396181384\n",
      "\n",
      "SVM, CharLevel Vectors: \n",
      "Train Accuracy:  0.9977936541290187\n",
      "Test Accuracy:  0.9890756302521009\n",
      "Confusion matrix:  [[1474    6]\n",
      " [  20  880]]\n",
      "F1_score:  0.9854423292273236\n"
     ]
    }
   ],
   "source": [
    "def svm_tune(x, y):\n",
    "\t\tCs = [0.001, 0.01, 0.1, 1, 10]\n",
    "\t\tgammas = [0.001, 0.01, 0.1, 1]\n",
    "\t\tgrid = {'C': Cs, 'gamma': gammas}\n",
    "\t\tsearch = GridSearchCV(svm.SVC(kernel='rbf'), grid)\n",
    "\t\tsearch.fit(x, y)\n",
    "\t\tsearch.best_params_\n",
    "\t\treturn search.best_params_\n",
    "\n",
    "# SVM on Bin Count Vectors\n",
    "print(\"\\nSVM, Binary Count Vectors: \")\n",
    "accuracy = train_model(svm.SVC(kernel='rbf', C=10, gamma=0.1), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# SVM on Count Vectors\n",
    "print(\"\\nSVM, Count Vectors: \")\n",
    "accuracy = train_model(svm.SVC(kernel='rbf', C=10, gamma=0.1), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# SVM on Word Level TF IDF Vectors\n",
    "print(\"\\nSVM, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(svm.SVC(kernel='rbf', C=10, gamma=0.1), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "print(\"\\nSVM, N-Gram Vectors: \")\n",
    "accuracy = train_model(svm.SVC(kernel='rbf', C=10, gamma=0.1), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "print(\"\\nSVM, CharLevel Vectors: \")\n",
    "accuracy = train_model(svm.SVC(kernel='rbf', C=10, gamma=0.1), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Linear SVM, Binary Count Vectors: \n",
      "Train Accuracy:  0.9998949359109056\n",
      "Test Accuracy:  0.9642857142857143\n",
      "Confusion matrix:  [[1458   22]\n",
      " [  63  837]]\n",
      "F1_score:  0.9516770892552587\n",
      "\n",
      "Linear SVM, Count Vectors: \n",
      "Train Accuracy:  0.999684807732717\n",
      "Test Accuracy:  0.9592436974789916\n",
      "Confusion matrix:  [[1453   27]\n",
      " [  70  830]]\n",
      "F1_score:  0.9447922595332954\n",
      "\n",
      "Linear SVM, WordLevel TF-IDF: \n",
      "Train Accuracy:  0.99516705190166\n",
      "Test Accuracy:  0.9596638655462185\n",
      "Confusion matrix:  [[1451   29]\n",
      " [  67  833]]\n",
      "F1_score:  0.945516458569807\n",
      "\n",
      "Linear SVM, N-Gram Vectors: \n",
      "Train Accuracy:  0.9501996217692793\n",
      "Test Accuracy:  0.8941176470588236\n",
      "Confusion matrix:  [[1420   60]\n",
      " [ 192  708]]\n",
      "F1_score:  0.8489208633093526\n",
      "\n",
      "Linear SVM, CharLevel Vectors: \n",
      "Train Accuracy:  0.9989493591090566\n",
      "Test Accuracy:  0.988655462184874\n",
      "Confusion matrix:  [[1475    5]\n",
      " [  22  878]]\n",
      "F1_score:  0.9848569826135727\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLinear SVM, Binary Count Vectors: \")\n",
    "accuracy = train_model(svm.LinearSVC(), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# SVM on Count Vectors\n",
    "print(\"\\nLinear SVM, Count Vectors: \")\n",
    "accuracy = train_model(svm.LinearSVC(), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# SVM on Word Level TF IDF Vectors\n",
    "print(\"\\nLinear SVM, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(svm.LinearSVC(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "print(\"\\nLinear SVM, N-Gram Vectors: \")\n",
    "accuracy = train_model(svm.LinearSVC(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "print(\"\\nLinear SVM, CharLevel Vectors: \")\n",
    "accuracy = train_model(svm.LinearSVC(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "RF, Binary Count Vectors: \n",
      "Train Accuracy:  1.0\n",
      "Test Accuracy:  0.9529411764705882\n",
      "Confusion matrix:  [[1470   10]\n",
      " [ 102  798]]\n",
      "F1_score:  0.9344262295081966\n",
      "\n",
      "RF, Count Vectors: \n",
      "Train Accuracy:  1.0\n",
      "Test Accuracy:  0.9512605042016806\n",
      "Confusion matrix:  [[1470   10]\n",
      " [ 106  794]]\n",
      "F1_score:  0.931924882629108\n",
      "\n",
      "RF, WordLevel TF-IDF: \n",
      "Train Accuracy:  0.9987392309308678\n",
      "Test Accuracy:  0.9575630252100841\n",
      "Confusion matrix:  [[1457   23]\n",
      " [  78  822]]\n",
      "F1_score:  0.9421203438395416\n",
      "\n",
      "RF, N-Gram Vectors: \n",
      "Train Accuracy:  0.9592351334313931\n",
      "Test Accuracy:  0.8953781512605042\n",
      "Confusion matrix:  [[1426   54]\n",
      " [ 195  705]]\n",
      "F1_score:  0.8499095840867993\n",
      "\n",
      "RF, CharLevel Vectors: \n",
      "Train Accuracy:  0.9998949359109056\n",
      "Test Accuracy:  0.984873949579832\n",
      "Confusion matrix:  [[1469   11]\n",
      " [  25  875]]\n",
      "F1_score:  0.9798432250839866\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRF, Binary Count Vectors: \")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=100), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# RF on Count Vectors\n",
    "print(\"\\nRF, Count Vectors: \")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "print(\"\\nRF, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# RF on Ngram Level TF IDF Vectors\n",
    "print(\"\\nRF, N-Gram Vectors: \")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# RF on Character Level TF IDF Vectors\n",
    "print(\"\\nRF, CharLevel Vectors: \")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "RF, Binary Count Vectors: \n",
      "Train Accuracy:  0.9349653288505989\n",
      "Test Accuracy:  0.9378151260504202\n",
      "Confusion matrix:  [[1359  121]\n",
      " [  27  873]]\n",
      "F1_score:  0.921858500527983\n",
      "\n",
      "RF, Count Vectors: \n",
      "Train Accuracy:  0.9349653288505989\n",
      "Test Accuracy:  0.9365546218487395\n",
      "Confusion matrix:  [[1355  125]\n",
      " [  26  874]]\n",
      "F1_score:  0.9204844655081623\n",
      "\n",
      "RF, WordLevel TF-IDF: \n",
      "Train Accuracy:  0.9360159697415423\n",
      "Test Accuracy:  0.9348739495798319\n",
      "Confusion matrix:  [[1351  129]\n",
      " [  26  874]]\n",
      "F1_score:  0.9185496584340513\n",
      "\n",
      "RF, N-Gram Vectors: \n",
      "Train Accuracy:  0.8743433494431603\n",
      "Test Accuracy:  0.8697478991596639\n",
      "Confusion matrix:  [[1469   11]\n",
      " [ 299  601]]\n",
      "F1_score:  0.7949735449735449\n",
      "\n",
      "RF, CharLevel Vectors: \n",
      "Train Accuracy:  0.9878125656650557\n",
      "Test Accuracy:  0.9827731092436974\n",
      "Confusion matrix:  [[1476    4]\n",
      " [  37  863]]\n",
      "F1_score:  0.976796830786644\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRF, Binary Count Vectors: \")\n",
    "accuracy = train_model(ensemble.GradientBoostingClassifier(n_estimators=100), binary_xtrain_count, train_y, binary_xtest_count)\n",
    "\n",
    "# RF on Count Vectors\n",
    "print(\"\\nRF, Count Vectors: \")\n",
    "accuracy = train_model(ensemble.GradientBoostingClassifier(n_estimators=100), xtrain_count, train_y, xtest_count)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "print(\"\\nRF, WordLevel TF-IDF: \")\n",
    "accuracy = train_model(ensemble.GradientBoostingClassifier(n_estimators=100), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "\n",
    "# RF on Ngram Level TF IDF Vectors\n",
    "print(\"\\nRF, N-Gram Vectors: \")\n",
    "accuracy = train_model(ensemble.GradientBoostingClassifier(n_estimators=100), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "\n",
    "# RF on Character Level TF IDF Vectors\n",
    "print(\"\\nRF, CharLevel Vectors: \")\n",
    "accuracy = train_model(ensemble.GradientBoostingClassifier(n_estimators=100), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}